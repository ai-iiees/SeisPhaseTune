{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c95f074",
   "metadata": {
    "id": "5c95f074",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*This code is necessary on colab to install SeisBench. If SeisBench is already installed on your machine, you can skip this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e49f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:58:59.251327Z",
     "iopub.status.busy": "2024-10-04T13:58:59.251327Z",
     "iopub.status.idle": "2024-10-04T13:58:59.257221Z",
     "shell.execute_reply": "2024-10-04T13:58:59.256219Z",
     "shell.execute_reply.started": "2024-10-04T13:58:59.251327Z"
    },
    "id": "a13e49f1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip -q install seisbench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e4590",
   "metadata": {
    "id": "960e4590",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*This cell is required to circumvent an issue with colab and obspy. For details, check this issue in the obspy documentation: https://github.com/obspy/obspy/issues/2547*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77bdb48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:58:59.739326Z",
     "iopub.status.busy": "2024-10-04T13:58:59.739326Z",
     "iopub.status.idle": "2024-10-04T13:58:59.744089Z",
     "shell.execute_reply": "2024-10-04T13:58:59.743086Z",
     "shell.execute_reply.started": "2024-10-04T13:58:59.739326Z"
    },
    "id": "a77bdb48",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     import obspy\n",
    "#     obspy.read()\n",
    "# except TypeError:\n",
    "#     # Needs to restart the runtime once, because obspy only works properly after restart.\n",
    "#     print('Stopping RUNTIME. If you run this code for the first time, this is expected. Colaboratory will restart automatically. Please run again.')\n",
    "#     exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f032984",
   "metadata": {
    "id": "7f032984",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training PhaseNet\n",
    "\n",
    "This tutorial shows how to train a model with SeisBench, using PhaseNet as an example. This brings together the three main components of SeisBench: data, models and generate.\n",
    "\n",
    "The tutorial is intended to highlight the basic principles of training models in SeisBench. However, this will not necessarily be best practice for more elaborate experiments. As a reference how to set up larger studies and which augmentations can be used for which models, we refer to the implementation of our pick benchmark at [https://github.com/seisbench/pick-benchmark](https://github.com/seisbench/pick-benchmark).\n",
    "\n",
    "*Note: As this tutorial brings together different parts of seisbench, it is recommended to go through the basic tutorials first before beginning this tutorial. In addition, this tutorial assumes some familiarity with pytorch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "lib_path = [r'C:\\Users\\ikahbasi\\OneDrive\\Applications\\GitHub\\SeisRoutine',\n",
    "            r'C:\\Users\\ikahb\\OneDrive\\Applications\\GitHub\\SeisRoutine']\n",
    "for path in lib_path:\n",
    "    sys.path.append(path)\n",
    "##########################################################################\n",
    "import SeisRoutine.catalog as src\n",
    "import SeisRoutine.waveform as srw\n",
    "import SeisRoutine.config as srconf\n",
    "import SeisRoutine.statistics as srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3943bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import myfuncs as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c1ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:00.322937Z",
     "iopub.status.busy": "2024-10-04T13:59:00.322937Z",
     "iopub.status.idle": "2024-10-04T13:59:05.831539Z",
     "shell.execute_reply": "2024-10-04T13:59:05.830537Z",
     "shell.execute_reply.started": "2024-10-04T13:59:00.322937Z"
    },
    "id": "689c1ea9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seisbench.data as sbd\n",
    "import seisbench.generate as sbg\n",
    "import seisbench.models as sbm\n",
    "from seisbench.util import worker_seeding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import ipynbname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8312085",
   "metadata": {},
   "source": [
    "# Define Some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_filename_and_path_of_the_running_code():\n",
    "    \"\"\"\n",
    "    Get the filename and directory path of the currently executing code.\n",
    "    \n",
    "    This function works for both regular Python scripts (.py files) and Jupyter Notebooks\n",
    "    (.ipynb files). For notebooks, it handles both VS Code's environment and standard\n",
    "    Jupyter environments.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing (directory_path, filename) of the running code.\n",
    "        \n",
    "    Note:\n",
    "        In Jupyter Notebook environments, returns the notebook name and path.\n",
    "        In regular Python scripts, returns the script name and path.\n",
    "    \"\"\"\n",
    "    _file = sys.argv[0]\n",
    "    name = os.path.basename(_file)\n",
    "    path = os.path.dirname(_file)\n",
    "    if name == \"ipykernel_launcher.py\":\n",
    "        try:\n",
    "            _file = globals()['__vsc_ipynb_file__']\n",
    "            name = os.path.basename(_file)\n",
    "            path = os.path.dirname(_file)\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            name = ipynbname.name()\n",
    "            path = ipynbname.path()\n",
    "    return path, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94c5f3",
   "metadata": {},
   "source": [
    "# Initializing the init file and starting logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_separator = \"+\" * 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2963655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:05.833538Z",
     "iopub.status.busy": "2024-10-04T13:59:05.833538Z",
     "iopub.status.idle": "2024-10-04T13:59:05.881843Z",
     "shell.execute_reply": "2024-10-04T13:59:05.881843Z",
     "shell.execute_reply.started": "2024-10-04T13:59:05.833538Z"
    }
   },
   "outputs": [],
   "source": [
    "init_cfg = srconf.load_config('0-init-cfg.yml')\n",
    "cfg_path = os.path.join(init_cfg.target_config_filepath,\n",
    "                        init_cfg.target_config_filename)\n",
    "cfg = srconf.load_config(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3fc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "srconf.configure_logging(level=cfg.log.level,\n",
    "                         log_format=cfg.log.format,\n",
    "                         mode=cfg.log.mode, colored_console=True,\n",
    "                         filepath=cfg.log.filepath,\n",
    "                         filename_prefix=cfg.log.filename_prefix,\n",
    "                         filename=cfg.log.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d1707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path, nb_name = getting_filename_and_path_of_the_running_code()\n",
    "msg = (f\"Logging has started for notebook: {nb_name}.\\n\"\n",
    "       f\"This file is located at: {nb_path}\\n\")\n",
    "logging.info(msg)\n",
    "logging.info(f\"Separator: {log_separator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126237a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = cfg.__str__()\n",
    "logging.info(f'Configuration File:\\n{msg}')\n",
    "logging.info(f\"Separator: {log_separator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173e4ed",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ps_pairs(metadata):\n",
    "    keys = metadata.keys()\n",
    "    df_p = metadata[[key for key in keys\n",
    "                     if (key.upper().startswith('trace_P'.upper())\n",
    "                         and\n",
    "                         key.upper().endswith('_arrival_sample'.upper())\n",
    "                         )\n",
    "                    ]]\n",
    "    p_condition = df_p.notna().any(axis=1)\n",
    "    ############################################################################\n",
    "    df_s = metadata[[key for key in keys\n",
    "                     if (key.upper().startswith('trace_S'.upper())\n",
    "                         and\n",
    "                         key.upper().endswith('_arrival_sample'.upper())\n",
    "                         )\n",
    "                    ]]\n",
    "    s_condition = df_s.notna().any(axis=1)\n",
    "    ############################################################################\n",
    "    ps_pairs_condition = s_condition == p_condition\n",
    "    return ps_pairs_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6933a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_data = [['bucket22$500,:3,:3001', '1386f728-f76a-417d-8dd5-711366dc4bcc,2014-09-04T10:35:37.400000Z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf8d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:09.978602Z",
     "iopub.status.busy": "2024-10-04T13:59:09.978602Z",
     "iopub.status.idle": "2024-10-04T13:59:10.571003Z",
     "shell.execute_reply": "2024-10-04T13:59:10.570006Z",
     "shell.execute_reply.started": "2024-10-04T13:59:09.978602Z"
    },
    "id": "dbbf8d17",
    "outputId": "fa32a588-a9be-4c83-e097-98cd8518c1f9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = sbd.WaveformDataset(\n",
    "    path=cfg.dataset.path,\n",
    "    sampling_rate=cfg.training.dataset.sampling_rate,\n",
    "    component_order=cfg.training.dataset.component_order,\n",
    "   # dimension_order=cfg.training.dataset.dimension_order # must recheck!\n",
    "   )\n",
    "# dataset.filter(~(dataset.metadata['trace_name'] == \"bucket2$268,:3,:3001\").values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.metadata['PS-pairs'] = find_ps_pairs(metadata=dataset.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0abfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dataset.metadata[dataset.metadata['PS-pairs']]\n",
    "# network = 'QM'\n",
    "# (df['station_network_code']==network).sum(), (dataset.metadata['station_network_code']==network).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebf286",
   "metadata": {},
   "outputs": [],
   "source": [
    "precentages = {'train': cfg.dataset.spliter.train,\n",
    "               'dev':   cfg.dataset.spliter.dev,\n",
    "               'test':  cfg.dataset.spliter.test}\n",
    "##################################################\n",
    "mf.dataset.manual_spliter(\n",
    "   dataset=dataset,\n",
    "   mode='PS-Pairs',\n",
    "   # mode='All',\n",
    "   precentages=precentages,\n",
    "   random=True,\n",
    "   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = dataset.train_dev_test()\n",
    "print(train, dev, test, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ii in range(len(dataset.metadata)):\n",
    "#     sample = dataset.get_sample(ii)\n",
    "#     _data, _meta = sample\n",
    "#     condition, quality = is_waveform_healthy(_data, axis=1, max_thr=1e-6, std_thr=1e-5)\n",
    "#     if not condition:\n",
    "#         # print(ii, quality)\n",
    "#         dataset.metadata.loc[_meta['index'], 'split'] = 'Undefined'\n",
    "#     else:\n",
    "#         snr_thr = 3\n",
    "#         snr = compute_snr(trace=_data, pick_idx=500, noise_window=100, signal_window=200)\n",
    "#         if (snr < snr_thr).all():\n",
    "#             # print(ii, snr)\n",
    "#             dataset.metadata.loc[_meta['index'], 'split'] = 'Undefined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414568b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(10):\n",
    "    sample = dataset.get_sample(ii)\n",
    "    _data, _meta = sample\n",
    "    plt.plot(_data.T)\n",
    "    plt.legend(['E', 'N', 'Z'])\n",
    "    plt.title(f'{_meta['index']} {_meta['station_code']}')\n",
    "    plt.show()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876fa35",
   "metadata": {
    "id": "d876fa35",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc83698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tapering:\n",
    "    def __init__(self, alpha=0.3, key='X'):\n",
    "        self.alpha = alpha  # Tapering Coefficient\n",
    "        if isinstance(key, str):\n",
    "            self.key = (key, key)\n",
    "        else:\n",
    "            self.key = key\n",
    "\n",
    "    def __call__(self, state_dict):\n",
    "        x, metadata = state_dict[self.key[0]]\n",
    "        taper = signal.windows.tukey(x.shape[-1], self.alpha)\n",
    "        x = x * taper\n",
    "        state_dict[self.key[1]] = (x, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b8ed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:12.003319Z",
     "iopub.status.busy": "2024-10-04T13:59:12.003319Z",
     "iopub.status.idle": "2024-10-04T13:59:12.008653Z",
     "shell.execute_reply": "2024-10-04T13:59:12.007650Z",
     "shell.execute_reply.started": "2024-10-04T13:59:12.003319Z"
    },
    "id": "930b8ed6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phase_dict = {\n",
    "    \"trace_p_arrival_sample\": \"P\",\n",
    "    \"trace_pP_arrival_sample\": \"P\",\n",
    "    \"trace_P_arrival_sample\": \"P\",\n",
    "    \"trace_P1_arrival_sample\": \"P\",\n",
    "\n",
    "    \"trace_Pg_arrival_sample\": \"P\",\n",
    "    \"trace_PG_arrival_sample\": \"P\",\n",
    "\n",
    "    \"trace_Pn_arrival_sample\": \"P\",\n",
    "    \"trace_PmP_arrival_sample\": \"P\",\n",
    "    \"trace_pwP_arrival_sample\": \"P\",\n",
    "    \"trace_pwPm_arrival_sample\": \"P\",\n",
    "    \n",
    "    \"trace_s_arrival_sample\": \"S\",\n",
    "    \"trace_S_arrival_sample\": \"S\",\n",
    "    \"trace_S1_arrival_sample\": \"S\",\n",
    "\n",
    "    \"trace_Sg_arrival_sample\": \"S\",\n",
    "    \"trace_SG_arrival_sample\": \"S\",\n",
    "\n",
    "    \"trace_SmS_arrival_sample\": \"S\",\n",
    "    \"trace_Sn_arrival_sample\": \"S\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train.metadata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a194bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = {}\n",
    "# for key, val in phase_dict.items():\n",
    "#     tmp[key.replace('trace', 'trace_manual')] = val\n",
    "\n",
    "# phase_dict = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf556356",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = 100\n",
    "augmentations = [\n",
    "    Tapering(),\n",
    "    sbg.Normalize(\n",
    "        demean_axis=-1,\n",
    "        amp_norm_axis=-1,\n",
    "        amp_norm_type=\"peak\"),\n",
    "    sbg.FixedWindow(\n",
    "        p0=-15*sps,\n",
    "        windowlen=1*60*sps,\n",
    "        strategy=\"pad\",\n",
    "        key='X'),\n",
    "    sbg.WindowAroundSample(\n",
    "        metadata_keys=list(phase_dict.keys()),\n",
    "        samples_before=2000,\n",
    "        windowlen=5000,\n",
    "        selection=\"random\",\n",
    "        strategy=\"variable\"),\n",
    "    sbg.GaussianNoise(\n",
    "        scale=(0, 0.02),\n",
    "        key='X'),\n",
    "    sbg.RandomWindow(\n",
    "        windowlen=3001),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(\n",
    "        label_columns=phase_dict,\n",
    "        model_labels=cfg.training.hyperparameters.phases,\n",
    "        sigma=30,\n",
    "        dim=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce52377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:13.083947Z",
     "iopub.status.busy": "2024-10-04T13:59:13.083947Z",
     "iopub.status.idle": "2024-10-04T13:59:13.090675Z",
     "shell.execute_reply": "2024-10-04T13:59:13.089680Z",
     "shell.execute_reply.started": "2024-10-04T13:59:13.083947Z"
    },
    "id": "cce52377",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = sbg.GenericGenerator(train)\n",
    "dev_generator = sbg.GenericGenerator(dev)\n",
    "test_generator = sbg.GenericGenerator(test)\n",
    "#######################################################\n",
    "train_generator.add_augmentations(augmentations)\n",
    "dev_generator.add_augmentations(augmentations)\n",
    "test_generator.add_augmentations(augmentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e75a3",
   "metadata": {
    "id": "454e75a3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's visualize a few training examples. Everytime you run the cell below, you'll see a different training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef0570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:14.092322Z",
     "iopub.status.busy": "2024-10-04T13:59:14.091324Z",
     "iopub.status.idle": "2024-10-04T13:59:14.519468Z",
     "shell.execute_reply": "2024-10-04T13:59:14.518465Z",
     "shell.execute_reply.started": "2024-10-04T13:59:14.092322Z"
    },
    "id": "d7ef0570",
    "outputId": "83997bbd-7cbf-4b2c-a687-dcb909472004",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_number = np.random.randint(len(dev_generator))\n",
    "sample = train_generator[sample_number]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "axs = fig.subplots(2, 1, sharex=True, gridspec_kw={\"hspace\": 0, \"height_ratios\": [3, 1]})\n",
    "axs[0].plot(sample[\"X\"].T)\n",
    "axs[1].plot(sample[\"y\"].T)\n",
    "plt.suptitle(sample_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005455e0",
   "metadata": {
    "id": "005455e0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SeisBench generators are pytorch datasets. Therefore, we can pass them to pytorch data loaders. These will automatically take care of parallel loading and batching. Here we create one loader for training and one for validation. We choose a batch size of 256 samples. This batch size should fit on most hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf2e42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:15.795321Z",
     "iopub.status.busy": "2024-10-04T13:59:15.795321Z",
     "iopub.status.idle": "2024-10-04T13:59:15.801346Z",
     "shell.execute_reply": "2024-10-04T13:59:15.800344Z",
     "shell.execute_reply.started": "2024-10-04T13:59:15.795321Z"
    },
    "id": "2bf2e42c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_generator,\n",
    "    batch_size=cfg.training.hyperparameters.batch_size,\n",
    "    shuffle=cfg.training.dataset.suffle,\n",
    "    num_workers=cfg.training.num_workers,\n",
    "    worker_init_fn=worker_seeding\n",
    ")\n",
    "dev_loader = DataLoader(\n",
    "    dev_generator,\n",
    "    batch_size=cfg.training.hyperparameters.batch_size,\n",
    "    shuffle=cfg.training.dataset.suffle,\n",
    "    num_workers=cfg.training.num_workers,\n",
    "    worker_init_fn=worker_seeding\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_generator,\n",
    "    batch_size=cfg.training.hyperparameters.batch_size,\n",
    "    shuffle=cfg.training.dataset.suffle,\n",
    "    num_workers=cfg.training.num_workers,\n",
    "    worker_init_fn=worker_seeding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9649cd",
   "metadata": {
    "id": "6b9649cd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Initialization\n",
    "\n",
    "We create a randomly initialized PhaseNet model using `seisbench.models`. If available, you can move your model onto the GPU for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596d33f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:07.971299Z",
     "iopub.status.busy": "2024-10-04T13:59:07.970300Z",
     "iopub.status.idle": "2024-10-04T13:59:07.984647Z",
     "shell.execute_reply": "2024-10-04T13:59:07.984647Z",
     "shell.execute_reply.started": "2024-10-04T13:59:07.971299Z"
    },
    "id": "b596d33f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(cfg.training.hyperparameters.manual_seed)\n",
    "model = sbm.PhaseNet(phases=cfg.training.hyperparameters.phases,\n",
    "                     norm=cfg.training.hyperparameters.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    msg = (\"Processor:\\n\"\n",
    "           f\"The {model.name} Model are running on GPU\\n\"\n",
    "           f\"GPU Name: {torch.cuda.get_device_name(0)}\\n\"\n",
    "           f\"Number of GPUs: {torch.cuda.device_count()}\\n\"\n",
    "           f\"CUDA available: {torch.cuda.is_available()}\\n\"\n",
    "           )\n",
    "else:\n",
    "    msg = mf.resources.get_cpu_info()\n",
    "    msg = (\"Processor:\\n\"\n",
    "           f\"The {model.name} Model are running on CPU\\n\"\n",
    "           + msg)\n",
    "    \n",
    "logging.info(msg)\n",
    "logging.info(f\"Separator: {log_separator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c0309",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b009a",
   "metadata": {
    "id": "0e9b009a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024bf3c",
   "metadata": {
    "id": "9024bf3c",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we got all components for training the model. What we still need to do is define the optimizer and the loss, and write the training and validation loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715e24b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:17.580005Z",
     "iopub.status.busy": "2024-10-04T13:59:17.580005Z",
     "iopub.status.idle": "2024-10-04T13:59:18.753785Z",
     "shell.execute_reply": "2024-10-04T13:59:18.752793Z",
     "shell.execute_reply.started": "2024-10-04T13:59:17.580005Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=eval(cfg.training.hyperparameters.learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5581f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:18.755784Z",
     "iopub.status.busy": "2024-10-04T13:59:18.755784Z",
     "iopub.status.idle": "2024-10-04T13:59:18.761534Z",
     "shell.execute_reply": "2024-10-04T13:59:18.760543Z",
     "shell.execute_reply.started": "2024-10-04T13:59:18.755784Z"
    },
    "id": "5ef5581f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(y_pred, y_true, eps=1e-5):\n",
    "    # vector cross entropy loss\n",
    "    h = y_true * torch.log(y_pred + eps)\n",
    "    h = h.mean(-1).sum(-1)  # Mean along sample dimension and sum along pick dimension\n",
    "    h = h.mean()  # Mean over batch axis\n",
    "    return -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4035919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:19.243319Z",
     "iopub.status.busy": "2024-10-04T13:59:19.242320Z",
     "iopub.status.idle": "2024-10-04T13:59:19.249894Z",
     "shell.execute_reply": "2024-10-04T13:59:19.248891Z",
     "shell.execute_reply.started": "2024-10-04T13:59:19.243319Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, optimizer):\n",
    "    lst_loss = []\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch_id, batch in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(batch[\"X\"].to(model.device))\n",
    "        loss = loss_fn(pred, batch[\"y\"].to(model.device))\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #\n",
    "        if batch_id % 5 == 0:\n",
    "            loss, current = loss.item(), batch_id * batch[\"X\"].shape[0]\n",
    "            logging.info(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            lst_loss.append((batch_id//5, loss))\n",
    "    return lst_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e5e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:19.819280Z",
     "iopub.status.busy": "2024-10-04T13:59:19.819280Z",
     "iopub.status.idle": "2024-10-04T13:59:19.825140Z",
     "shell.execute_reply": "2024-10-04T13:59:19.824137Z",
     "shell.execute_reply.started": "2024-10-04T13:59:19.819280Z"
    },
    "id": "4b9e5e96",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_loop(dataloader):\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    model.eval()  # close the model for evaluation\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(dataloader):\n",
    "            # print(index, batch)\n",
    "            pred = model(batch[\"X\"].to(model.device))\n",
    "            test_loss += loss_fn(pred, batch[\"y\"].to(model.device)).item()\n",
    "\n",
    "    model.train()  # re-open model for training stage\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    logging.info(f\"Test avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368347c2",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e07183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(\n",
    "#     level=logging.DEBUG,\n",
    "#     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "#     force=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e647b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Find problem in data set.\n",
    "# batch_samples = []\n",
    "# for i in range(len(test_loader.dataset)):\n",
    "#     try:\n",
    "#         sample = test_loader.dataset[i]\n",
    "#         batch_samples.append(sample)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error loading sample {i}: {e}\")\n",
    "#         data, metadata = dev.get_sample(i)\n",
    "\n",
    "\n",
    "# i = 3624\n",
    "# plt.plot(dev.get_sample(i)[0].T)\n",
    "# plt.show()\n",
    "# plt.plot(dev_loader.dataset[i]['X'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e16fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.training.hyperparameters.learning_rates = ['1e-3', '1e-4']\n",
    "# cfg.training.hyperparameters.epochs_for_each_learning_rate = [2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a1cd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T13:59:20.390535Z",
     "iopub.status.busy": "2024-10-04T13:59:20.389536Z",
     "iopub.status.idle": "2024-10-04T14:12:20.595283Z",
     "shell.execute_reply": "2024-10-04T14:12:20.595283Z",
     "shell.execute_reply.started": "2024-10-04T13:59:20.390535Z"
    },
    "id": "975a1cd8",
    "outputId": "4a236c8a-cb9a-4452-c4c2-753c0af0faaa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_loss = pd.DataFrame(columns=['epoch', 'batch', 'loss_train', 'loss_test'])\n",
    "###\n",
    "for learning_rate, epochs in zip(cfg.training.hyperparameters.learning_rates,\n",
    "                                 cfg.training.hyperparameters.epochs_for_each_learning_rate):\n",
    "    logging.info(f\"Main Learning-Rate: {learning_rate}\\n\" + \"-\"*70)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=eval(learning_rate))\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer=optimizer, mode='min',\n",
    "        factor=cfg.training.hyperparameters.lr_scheduler.ReduceLROnPlateau.factor,\n",
    "        patience=cfg.training.hyperparameters.lr_scheduler.ReduceLROnPlateau.patience,\n",
    "        threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "    for epoch in range(epochs):\n",
    "        learning_rate = scheduler.get_last_lr()[0]\n",
    "        logging.info(f\"Learning-Rate: {learning_rate} Epoch: {epoch+1}\\n\" + \"-\"*70)\n",
    "        train_loss = train_loop(dataloader=train_loader,\n",
    "                                optimizer=optimizer)\n",
    "        test_loss = test_loop(dev_loader)\n",
    "        scheduler.step(test_loss)\n",
    "        #\n",
    "        df_loss_tmp = pd.DataFrame(train_loss, columns=['batch', 'loss_train'])\n",
    "        df_loss_tmp['epoch'] = epoch\n",
    "        df_loss_tmp['loss_test'] = None\n",
    "        last_none_index = len(df_loss_tmp) - 1\n",
    "        df_loss_tmp.at[last_none_index, \"loss_test\"] = test_loss\n",
    "        df_loss = pd.concat([df_loss, df_loss_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15bf99c",
   "metadata": {},
   "source": [
    "# Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.training.output_model.filepath = r'F:\\Models\\PhaseNet_Trained_single_networks'\n",
    "# cfg.training.output_model.version_str= r'14040318_1800_PS-Pairs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.abspath(cfg.training.output_model.filepath), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a199681",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy(init_cfg.target_config_filename,\n",
    "            f'{cfg.training.output_model.filepath}/cfg-{cfg.training.output_model.version_str}.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fd1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss.to_csv(\n",
    "    os.path.join(cfg.training.output_model.filepath,\n",
    "                 f'loss_{cfg.training.output_model.version_str}.csv')\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff561a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:12:36.802843Z",
     "iopub.status.busy": "2024-10-04T14:12:36.802843Z",
     "iopub.status.idle": "2024-10-04T14:12:36.827105Z",
     "shell.execute_reply": "2024-10-04T14:12:36.826102Z",
     "shell.execute_reply.started": "2024-10-04T14:12:36.802843Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\n",
    "    path=os.path.join(cfg.training.output_model.filepath,\n",
    "                      cfg.training.output_model.filename_prefix),\n",
    "    weights_docstring=cfg.__str__(),\n",
    "    version_str=cfg.training.output_model.version_str\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db01326e",
   "metadata": {},
   "source": [
    "# Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aedc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import plotly.express\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef31e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = pd.read_csv(\n",
    "            os.path.join(\n",
    "                cfg.training.output_model.filepath,\n",
    "                f'loss_{cfg.training.output_model.version_str}.csv'\n",
    "                )\n",
    "            )\n",
    "df_loss['index'] = df_loss.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b308db",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_train = df_loss.index.values\n",
    "loss_train = df_loss['loss_train']\n",
    "###\n",
    "loss_test = df_loss['loss_test']\n",
    "\n",
    "idx_test = df_loss.index.values[loss_test.notna()]\n",
    "loss_test = loss_test.values[loss_test.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict({'scrollZoom': True})\n",
    "\n",
    "fig = px.line(\n",
    "    df_loss, \n",
    "    x=\"index\", \n",
    "    y=[\"loss_train\", \"loss_test\"], \n",
    "    markers=True  # Adding point marker\n",
    ")\n",
    "fig.update_traces(connectgaps=True)\n",
    "fig.update_layout(yaxis_type=\"log\")\n",
    "\n",
    "fig.show(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = dict({'scrollZoom': True})\n",
    "# #\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=idx_train, y=loss_train, mode='lines', name='Train Loss'))\n",
    "# fig.add_trace(go.Scatter(x=idx_test, y=loss_test, mode='lines+markers', name='Test Loss'))\n",
    "# fig.update_layout(yaxis_type=\"log\")\n",
    "# fig.show(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0ef68",
   "metadata": {
    "id": "bdd0ef68",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Remarks\n",
    "\n",
    "As discussed in the data basics tutorial, loading a SeisBench dataset only means loading the metadata into memory. The waveforms are only loaded once they are requested to save memory. By default, waveforms are **not** cached in memory. For training, this means that the data needs to be read from the file in every epoch again. Depending on your hardware, this will take a lot of time. To solve this issue, you can set the `cache` option, when creating the dataset. Then, all you have to do is call `preload_waveforms` and the data will be loaded into memory and automatically cached. For most practical applications, this option is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee75eed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a4dfcf5",
   "metadata": {},
   "source": [
    "# Trying for making constant weights in initialization of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d753298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "torch.manual_seed(42)\n",
    "cnn1 = nn.Conv1d(2, 1, 3, padding=\"same\")\n",
    "cnn2 = nn.Conv1d(2, 1, 3, padding=\"same\")\n",
    "cnn1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b6396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f2310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "seisbench_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
